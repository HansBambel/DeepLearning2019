{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "data = sio.loadmat(\"Xtrain.mat\")[\"Xtrain\"]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaler and fit it on data\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(data)\n",
    "\n",
    "data_normed = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(data)\n",
    "plt.title(\"Data\")\n",
    "plt.xlabel(\"Time step\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(data_normed)\n",
    "plt.title(\"Data (normalized)\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsize = 100\n",
    "\n",
    "def evaluate_model(inp, target, epochs=1, verbose=2):\n",
    "    # encode targets\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(32, return_sequences=True, input_shape=(inp.shape[1], 1), dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    # fit model\n",
    "    # model.fit(trainX, trainy_enc, epochs=50, verbose=0)\n",
    "#     early_stopping_monitor = EarlyStopping(monitor='loss', patience=3)\n",
    "    history = model.fit(inp, target, epochs=epochs, validation_split=0.1, verbose=verbose)\n",
    "    # evaluate the model\n",
    "    # _, test_acc = model.evaluate(testX, testY, verbose=0)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data (model is trained on sequence and should predict the next timestep)\n",
    "targetIndex = np.array(range(inputsize, len(data)))\n",
    "\n",
    "# Compare normalized and not normalized data (data/data_normed)\n",
    "inputdata = np.array([data_normed[ind-inputsize:ind] for ind in targetIndex])\n",
    "target = data_normed[targetIndex]\n",
    "\n",
    "print(f'inputdata Shape {inputdata.shape}')\n",
    "print(f'target Shape {target.shape}')\n",
    "\n",
    "# Split into train and test\n",
    "splitInd = int(len(inputdata)*0.9)\n",
    "trainX = inputdata[:splitInd]\n",
    "trainY = target[:splitInd]\n",
    "testX = inputdata[splitInd:]\n",
    "testY = target[splitInd:]\n",
    "print(\"trainX.shape\", trainX.shape)\n",
    "print(\"trainY.shape\", trainY.shape)\n",
    "print(\"testX.shape\", testX.shape)\n",
    "print(\"testY.shape\", testY.shape)\n",
    "\n",
    "model, history = evaluate_model(trainX, trainY, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(testX)\n",
    "pred_unscaled = scaler.inverse_transform(pred)\n",
    "testY_unscaled = scaler.inverse_transform(testY)\n",
    "print(\"pred.shape \", pred.shape)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Normalized prediction')\n",
    "plt.plot(pred, 'o', c='r', label=\"Predicted\")\n",
    "plt.plot(testY, 'o', c='g', label=\"Target\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Unscaled prediction')\n",
    "plt.plot(pred_unscaled, 'o', c='r', label=\"Predicted\")\n",
    "plt.plot(testY_unscaled, 'o', c='g', label=\"Target\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Loss development')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to implement K-Fold crossvalidation and save the n-best models to use as ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO create a proper validation set to test ensembles\n",
    "\n",
    "models = []\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds)\n",
    "for train_index, test_index in kf.split(inputdata, target):\n",
    "    trainX, trainY = inputdata[train_index], target[train_index]\n",
    "    testX, testY = inputdata[test_index], target[test_index]\n",
    "\n",
    "    model, history = evaluate_model(trainX, trainY, epochs=50, verbose=2)\n",
    "    models.append(model)\n",
    "    score = model.evaluate(testX, testY)[0]\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(models, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in models]\n",
    "    # median across ensemble members\n",
    "    result = np.median(yhats, axis=0)\n",
    "    return result\n",
    " \n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(models, n_models, testX, testy):\n",
    "    # select a subset of members\n",
    "    subset = models[:n_models]\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(subset, testX)\n",
    "    # calculate accuracy\n",
    "#     print(\"testy \", testy)\n",
    "#     print(\"yhat \", yhat)\n",
    "    return mean_squared_error(testy, yhat)\n",
    "    \n",
    "\n",
    "validationX, validationY = testX, testY\n",
    "single_MSEs, ensemble_MSEs = [], []\n",
    "for i in range(1, n_folds+1):\n",
    "    ensemble_MSE = evaluate_n_members(models, i, validationX, validationY)\n",
    "    # looks at accuracy right now (maybe bad?)\n",
    "    single_MSE, _ = models[i-1].evaluate(validationX, validationY, verbose=0)\n",
    "    print('> %d: single=%.3f, ensemble=%.3f' % (i, single_MSE, ensemble_MSE))\n",
    "    ensemble_MSEs.append(ensemble_MSE)\n",
    "    single_MSEs.append(single_MSE)\n",
    "# plot score vs number of ensemble members\n",
    "print('MSE %.3f (%.3f)' % (np.mean(single_MSEs), np.std(single_MSEs)))\n",
    "x_axis = [i for i in range(1, n_folds+1)]\n",
    "plt.plot(x_axis, single_MSEs, marker='o', linestyle='None')\n",
    "plt.plot(x_axis, ensemble_MSEs, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ensemble_predictions(models[:6], testX)\n",
    "pred_unscaled = scaler.inverse_transform(pred)\n",
    "testY_unscaled = scaler.inverse_transform(testY)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Normalized prediction')\n",
    "plt.plot(pred, 'o', c='r', label=\"Predicted\")\n",
    "plt.plot(testY, 'o', c='g', label=\"Target\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Unscaled prediction')\n",
    "plt.plot(pred_unscaled, 'o', c='r', label=\"Predicted\")\n",
    "plt.plot(testY_unscaled, 'o', c='g', label=\"Target\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(testY_unscaled, pred_unscaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
